{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just get a quick sparsity overview of the methods so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE_PATH_DATA = '../data/'\n",
    "BASE_PATH_DATA = '/scratch/ns3429/sparse-subset/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "b1 = 0.9\n",
    "b2 = 0.999\n",
    "img_size = 28\n",
    "channels = 1\n",
    "\n",
    "log_interval = 20\n",
    "\n",
    "\n",
    "z_size = 40\n",
    "\n",
    "n = 28 * 28\n",
    "\n",
    "# from running\n",
    "# EPSILON = np.finfo(tf.float32.as_numpy_dtype).tiny\n",
    "#EPSILON = 1.1754944e-38\n",
    "EPSILON = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Device\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sio.loadmat(BASE_PATH_DATA + 'zeisel/zeisel_data.mat')\n",
    "data= a['zeisel_data'].T\n",
    "N,d=data.shape\n",
    "for i in range(d):\n",
    "    #data[i,:]=data[i,:]/np.linalg.norm(data[i,:])\n",
    "    #mi = np.mean(data[:,i])\n",
    "    #std = np.std(data[:,i])\n",
    "    #data[:,i] = (data[:,i] - mi) / std\n",
    "    ma = np.max(data[:,i])\n",
    "    mi = np.min(data[:,i])\n",
    "    data[:, i] = (data[:, i] - mi) / (ma - mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = np.random.permutation(np.arange(data.shape[0]))\n",
    "upto = int(.8 * len(data))\n",
    "\n",
    "train_data = data[slices[:upto]]\n",
    "test_data = data[slices[upto:]]\n",
    "\n",
    "train_data = Tensor(train_data).to(device)\n",
    "test_data = Tensor(test_data).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2263, device='cuda:0')\n",
      "tensor(0.2223, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.std(dim = 0).mean())\n",
    "print(test_data.std(dim = 0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_per_autoencoder(x, mu_x, logvar_x, mu_latent, logvar_latent):\n",
    "    # BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    # BCE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    loss_rec = -torch.sum(\n",
    "            (-0.5 * np.log(2.0 * np.pi))\n",
    "            + (-0.5 * logvar_x)\n",
    "            + ((-0.5 / torch.exp(logvar_x)) * (x - mu_x) ** 2.0))\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar_latent - mu_latent.pow(2) - logvar_latent.exp())\n",
    "    #print(loss_rec.item(), KLD.item())\n",
    "    return loss_rec + 130640 * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KLD of D(P_1||P_2) where P_i are Gaussians, assuming diagonal\n",
    "def kld_joint_autoencoders(mu_1, mu_2, logvar_1, logvar_2):\n",
    "    # equation 6 of Tutorial on Variational Autoencoders by Carl Doersch\n",
    "    # https://arxiv.org/pdf/1606.05908.pdf\n",
    "    mu_12 = mu_1 - mu_2\n",
    "    kld = 0.5 * (-1 - (logvar_1 - logvar_2) + mu_12.pow(2) / logvar_2.exp() + torch.exp(logvar_1 - logvar_2))\n",
    "    #print(kld.shape)\n",
    "    kld = torch.sum(kld, dim = 1)\n",
    "    \n",
    "    return kld.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for joint\n",
    "def loss_function_joint(x, ae_1, ae_2):\n",
    "    # assuming that both autoencoders return recon_x, mu, and logvar\n",
    "    # try to make ae_1 the vanilla vae\n",
    "    # ae_2 should be the L1 penalty VAE\n",
    "    mu_x_1, logvar_x_1, mu_latent_1, logvar_latent_1 = ae_1(x)\n",
    "    mu_x_2, logvar_x_2, mu_latent_2, logvar_latent_2 = ae_2(x)\n",
    "    \n",
    "    loss_vae_1 = loss_function_per_autoencoder(x, mu_x_1, logvar_x_1, mu_latent_1, logvar_latent_1)\n",
    "    loss_vae_2 = loss_function_per_autoencoder(x, mu_x_2, logvar_x_2, mu_latent_2, logvar_latent_2)\n",
    "    joint_kld_loss = kld_joint_autoencoders(mu_latent_1, mu_latent_2, logvar_latent_1, logvar_latent_1)\n",
    "    #print(\"Losses\")\n",
    "    #print(loss_vae_1)\n",
    "    #print(loss_vae_2)\n",
    "    #print(joint_kld_loss)\n",
    "    return loss_vae_1, loss_vae_2, joint_kld_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does L1 work if we normalize after every step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 VAE model we are loading\n",
    "class VAE_l1_diag(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, z_size):\n",
    "        super(VAE_l1_diag, self).__init__()\n",
    "        \n",
    "        self.diag = nn.Parameter(torch.normal(torch.zeros(input_size), \n",
    "                                 torch.ones(input_size)).to(device).requires_grad_(True))\n",
    "        \n",
    "        # self.fc1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.fc21 = nn.Linear(hidden_layer_size, z_size)\n",
    "        self.fc22 = nn.Linear(hidden_layer_size, z_size)\n",
    "        self.fc3 = nn.Linear(z_size, hidden_layer_size)\n",
    "        self.fc4 = nn.Linear(hidden_layer_size, input_size)\n",
    "        self.fc5 = nn.Linear(hidden_layer_size, input_size)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_layer_size),\n",
    "            nn.BatchNorm1d(hidden_layer_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "            nn.BatchNorm1d(hidden_layer_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "            nn.BatchNorm1d(hidden_layer_size),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc3_bn = nn.BatchNorm1d(hidden_layer_size)\n",
    "\n",
    "    def encode(self, x):\n",
    "        self.selection_layer = torch.diag(self.diag)\n",
    "        h0 = torch.mm(x, self.selection_layer)\n",
    "        h1 = self.encoder(h0)\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.leaky_relu(self.fc3_bn(self.fc3(z)))\n",
    "        mu_x = F.leaky_relu(self.fc4(h))\n",
    "        #mu_x = self.fc4(h)\n",
    "        logvar_x = self.fc5(h)\n",
    "        return mu_x, logvar_x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu_latent, logvar_latent = self.encode(x)\n",
    "        z = self.reparameterize(mu_latent, logvar_latent)\n",
    "        mu_x, logvar_x = self.decode(z)\n",
    "        return mu_x, logvar_x, mu_latent, logvar_latent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_l1(df, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    permutations = torch.randperm(df.shape[0])\n",
    "    for i in range(math.ceil(len(df)/batch_size)):\n",
    "        batch_ind = permutations[i * batch_size : (i+1) * batch_size]\n",
    "        batch_data = df[batch_ind, :]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        mu_x, logvar_x, mu_latent, logvar_latent = model(batch_data)\n",
    "        loss = loss_function_per_autoencoder(batch_data, mu_x, logvar_x, mu_latent, logvar_latent)\n",
    "        loss += 1000000 * torch.norm(model.diag, p = 1)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.diag.data /= torch.norm(model.diag.data, p = 2)\n",
    "        \n",
    "        if i % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(batch_data), len(df),\n",
    "                100. * i * len(batch_data) / len(df),\n",
    "                loss.item() / len(batch_data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(df)))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(df, model, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    inds = np.arange(df.shape[0])\n",
    "    with torch.no_grad():\n",
    "        for i in range(math.ceil(len(df)/batch_size)):\n",
    "            batch_ind = inds[i * batch_size : (i+1) * batch_size]\n",
    "            batch_data = df[batch_ind, :]\n",
    "            batch_data = batch_data.to(device)\n",
    "            mu_x, logvar_x, mu_latent, logvar_latent = model(batch_data)\n",
    "            test_loss += loss_function_per_autoencoder(batch_data, mu_x, logvar_x, mu_latent, logvar_latent).item()\n",
    "\n",
    "\n",
    "    test_loss /= len(df)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l1_diag = VAE_l1_diag(input_size, 200, 50)\n",
    "\n",
    "model_l1_diag.to(device)\n",
    "model_l1_optimizer = torch.optim.Adam(model_l1_diag.parameters(), \n",
    "                                            lr=lr,\n",
    "                                            betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2404 (0%)]\tLoss: 49456560.000000\n",
      "Train Epoch: 1 [1280/2404 (53%)]\tLoss: 577130.812500\n",
      "====> Epoch: 1 Average loss: 1965976.6955\n",
      "====> Test set loss: 4905.2408\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "        train_l1(train_data, model_l1_diag, model_l1_optimizer, epoch)\n",
    "        test(test_data, model_l1_diag, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    1,   26,  304, 1826, 1175,  660,    8,    0]),\n",
       " array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02,\n",
       "        1.e-01, 1.e+00, 1.e+01]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [10**(-i) for i in range(10)]\n",
    "bins.reverse()\n",
    "bins += [10]\n",
    "np.histogram(model_l1_diag.diag.abs().clone().detach().cpu().numpy(), bins = bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    train_pred = model_l1_diag(train_data[0:64, :])[0]\n",
    "    train_pred[train_pred < 0.001] = 0 \n",
    "\n",
    "    test_pred = model_l1_diag(test_data[0:64,:])[0]\n",
    "    test_pred[test_pred < 0.001] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5910, 0.2284, 0.3724,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0')"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1708, device='cuda:0')\n",
      "tensor(1105, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(test_pred[0,:] != 0))\n",
    "print(torch.sum(test_data[0,:] != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6312, device='cuda:0')\n",
      "tensor(1.5704, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(torch.sum((train_pred - train_data[0:64, :]).abs()) / 64/500)\n",
    "    print(torch.sum((test_pred - test_data[0:64, :]).abs()) / 64/500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try Pretrained VAE and then gumble trick with it\n",
    "\n",
    "Then try joint training VAE and Gumbel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla VAE model\n",
    "# try with gaussian decoder\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, z_size):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        #self.fc1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.fc21 = nn.Linear(hidden_layer_size, z_size)\n",
    "        self.fc22 = nn.Linear(hidden_layer_size, z_size)\n",
    "        self.fc3 = nn.Linear(z_size, hidden_layer_size)\n",
    "        self.fc4 = nn.Linear(hidden_layer_size, input_size)\n",
    "        self.fc5 = nn.Linear(hidden_layer_size, input_size)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_layer_size),\n",
    "            nn.BatchNorm1d(hidden_layer_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "            nn.BatchNorm1d(hidden_layer_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "            nn.BatchNorm1d(hidden_layer_size),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc3_bn = nn.BatchNorm1d(hidden_layer_size)\n",
    "        \n",
    "        #self.decoder = nn.Sequential()\n",
    "\n",
    "    def encode(self, x):\n",
    "        #h1 = F.relu(self.fc1(x))\n",
    "        h1 = self.encoder(x)\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):    \n",
    "        h = F.leaky_relu(self.fc3_bn(self.fc3(z)))\n",
    "        mu_x = F.leaky_relu(self.fc4(h))\n",
    "        #mu_x = self.fc4(h)\n",
    "        logvar_x = self.fc5(h)\n",
    "        return mu_x, logvar_x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu_latent, logvar_latent = self.encode(x)\n",
    "        z = self.reparameterize(mu_latent, logvar_latent)\n",
    "        mu_x, logvar_x = self.decode(z)\n",
    "        return mu_x, logvar_x, mu_latent, logvar_latent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain VAE First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_vae = VAE(input_size, 200, 50)\n",
    "\n",
    "pretrain_vae.to(device)\n",
    "pretrain_vae_optimizer = torch.optim.Adam(pretrain_vae.parameters(), \n",
    "                                            lr=lr,\n",
    "                                            betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    permutations = torch.randperm(df.shape[0])\n",
    "    for i in range(math.ceil(len(df)/batch_size)):\n",
    "        batch_ind = permutations[i * batch_size : (i+1) * batch_size]\n",
    "        batch_data = df[batch_ind, :]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        mu_x, logvar_x, mu_latent, logvar_latent = model(batch_data)\n",
    "        loss = loss_function_per_autoencoder(batch_data, mu_x, logvar_x, mu_latent, logvar_latent)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(batch_data), len(df),\n",
    "                100. * i * len(batch_data)/ len(df),\n",
    "                loss.item() / len(batch_data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(df)))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2404 (0%)]\tLoss: 827268.125000\n",
      "Train Epoch: 1 [1280/2404 (53%)]\tLoss: 28012.517578\n",
      "====> Epoch: 1 Average loss: 110572.5380\n",
      "====> Test set loss: 11155.1012\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "        train(train_data, pretrain_vae, pretrain_vae_optimizer, epoch)\n",
    "        test(test_data, pretrain_vae, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    train_pred = pretrain_vae(train_data[0:64, :])[0]\n",
    "    train_pred[train_pred < 0.001] = 0 \n",
    "\n",
    "    test_pred = pretrain_vae(test_data[0:64,:])[0]\n",
    "    test_pred[test_pred < 0.001] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6304, device='cuda:0')\n",
      "tensor(1.5734, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(torch.sum((train_pred - train_data[0:64, :]).abs()) / 64/500)\n",
    "    print(torch.sum((test_pred - test_data[0:64, :]).abs()) / 64/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1873, device='cuda:0')\n",
      "tensor(1105, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(test_pred[0,:] != 0))\n",
    "print(torch.sum(test_data[0,:] != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pretrain_vae.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc21): Linear(in_features=200, out_features=50, bias=True)\n",
       "  (fc22): Linear(in_features=200, out_features=50, bias=True)\n",
       "  (fc3): Linear(in_features=50, out_features=200, bias=True)\n",
       "  (fc4): Linear(in_features=200, out_features=4000, bias=True)\n",
       "  (fc5): Linear(in_features=200, out_features=4000, bias=True)\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=4000, out_features=200, bias=True)\n",
       "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (4): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (7): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (fc3_bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_vae.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Gumbel with the Pre-Trained VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pre_trained(df, model, optimizer, epoch, pretrained_model):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    permutations = torch.randperm(df.shape[0])\n",
    "    for i in range(math.ceil(len(df)/batch_size)):\n",
    "        batch_ind = permutations[i * batch_size : (i+1) * batch_size]\n",
    "        batch_data = df[batch_ind, :]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        mu_x, logvar_x, mu_latent, logvar_latent = model(batch_data)\n",
    "        with torch.no_grad():\n",
    "            _, _, mu_latent_2, logvar_latent_2 = pretrained_model(batch_data)\n",
    "        \n",
    "        loss = loss_function_per_autoencoder(batch_data, mu_x, logvar_x, mu_latent, logvar_latent)\n",
    "        loss += 1000*F.mse_loss(mu_latent, mu_latent_2, reduction = 'sum')\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(batch_data), len(df),\n",
    "                100. * i * len(batch_data)/ len(df),\n",
    "                loss.item() / len(batch_data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel_keys(w):\n",
    "    # sample some gumbels\n",
    "    uniform = (1.0 - EPSILON) * torch.rand_like(w) + EPSILON\n",
    "    z = torch.log(-torch.log(uniform))\n",
    "    w = w + z\n",
    "    return w\n",
    "\n",
    "\n",
    "#equations 3 and 4 and 5\n",
    "def continuous_topk(w, k, t, separate=False):\n",
    "    softmax = nn.Softmax(dim = -1)\n",
    "    khot_list = []\n",
    "    onehot_approx = torch.zeros_like(w, dtype = torch.float32)\n",
    "    for i in range(k):\n",
    "        ### conver the following into pytorch\n",
    "        #khot_mask = tf.maximum(1.0 - onehot_approx, EPSILON)\n",
    "        max_mask = 1 - onehot_approx < EPSILON\n",
    "        khot_mask = 1 - onehot_approx\n",
    "        khot_mask[max_mask] = EPSILON\n",
    "        \n",
    "        w += torch.log(khot_mask)\n",
    "        #onehot_approx = tf.nn.softmax(w / t, axis=-1)\n",
    "        onehot_approx = softmax(w/t)\n",
    "        khot_list.append(onehot_approx)\n",
    "    if separate:\n",
    "        return torch.stack(khot_list)\n",
    "    else:\n",
    "        return torch.sum(torch.stack(khot_list), dim = 0) \n",
    "\n",
    "\n",
    "def sample_subset(w, k, t=0.1):\n",
    "    '''\n",
    "    Args:\n",
    "        w (Tensor): Float Tensor of weights for each element. In gumbel mode\n",
    "            these are interpreted as log probabilities\n",
    "        k (int): number of elements in the subset sample\n",
    "        t (float): temperature of the softmax\n",
    "    '''\n",
    "    w = gumbel_keys(w)\n",
    "    return continuous_topk(w, k, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 VAE model we are loading\n",
    "class VAE_Gumbel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, z_size, k, t = 0.1):\n",
    "        super(VAE_Gumbel, self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.t = t\n",
    "        \n",
    "        self.weight_creator = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_layer_size),\n",
    "            nn.BatchNorm1d(hidden_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_size, input_size)\n",
    "        )\n",
    "        \n",
    "        #self.fc1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        #self.fcextra = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.fc21 = nn.Linear(hidden_layer_size, z_size)\n",
    "        self.fc22 = nn.Linear(hidden_layer_size, z_size)\n",
    "        self.fc3 = nn.Linear(z_size, hidden_layer_size)\n",
    "        self.fc4 = nn.Linear(hidden_layer_size, input_size)\n",
    "        self.fc5 = nn.Linear(hidden_layer_size, input_size)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_layer_size),\n",
    "            nn.BatchNorm1d(hidden_layer_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "            nn.BatchNorm1d(hidden_layer_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "            nn.BatchNorm1d(hidden_layer_size),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc3_bn = nn.BatchNorm1d(hidden_layer_size)\n",
    "\n",
    "    def encode(self, x):\n",
    "        w = self.weight_creator(x)\n",
    "        subset_indices = sample_subset(w, self.k, self.t)\n",
    "        x = x * subset_indices\n",
    "        h1 = self.encoder(x)\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.leaky_relu(self.fc3_bn(self.fc3(z)))\n",
    "        mu_x = F.leaky_relu(self.fc4(h))\n",
    "        #mu_x = self.fc4(h)\n",
    "        logvar_x = self.fc5(h)\n",
    "        return mu_x, logvar_x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu_latent, logvar_latent = self.encode(x)\n",
    "        z = self.reparameterize(mu_latent, logvar_latent)\n",
    "        mu_x, logvar_x = self.decode(z)\n",
    "        return mu_x, logvar_x, mu_latent, logvar_latent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_gumbel_with_pre = VAE_Gumbel(input_size, 200, 50, k = 50)\n",
    "vae_gumbel_with_pre.to(device)\n",
    "vae_gumbel_with_pre_optimizer = torch.optim.Adam(vae_gumbel_with_pre.parameters(), \n",
    "                                                lr=lr, \n",
    "                                                betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2404 (0%)]\tLoss: 802522.687500\n",
      "Train Epoch: 1 [1280/2404 (53%)]\tLoss: 51021.445312\n",
      "====> Epoch: 1 Average loss: 162977.3032\n",
      "====> Test set loss: 6603.3549\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "        train_pre_trained(train_data, vae_gumbel_with_pre, vae_gumbel_with_pre_optimizer, epoch, pretrain_vae)\n",
    "        test(test_data, vae_gumbel_with_pre, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    train_pred = vae_gumbel_with_pre(train_data[0:64, :])[0]\n",
    "    train_pred[train_pred < 0.001] = 0 \n",
    "\n",
    "    test_pred = vae_gumbel_with_pre(test_data[0:64,:])[0]\n",
    "    test_pred[test_pred < 0.001] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6257, device='cuda:0')\n",
      "tensor(1.5634, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(torch.sum((train_pred - train_data[0:64, :]).abs()) / 64/500)\n",
    "    print(torch.sum((test_pred - test_data[0:64, :]).abs()) / 64/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1881, device='cuda:0')\n",
      "tensor(1105, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(test_pred[0,:] != 0))\n",
    "print(torch.sum(test_data[0,:] != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1 should be vanilla\n",
    "\n",
    "def train_joint(df, model1, model2, optimizer, epoch):\n",
    "    model1.train()\n",
    "    model2.train()\n",
    "    train_loss = 0\n",
    "    permutations = torch.randperm(df.shape[0])\n",
    "    for i in range(math.ceil(len(df)/batch_size)):\n",
    "        batch_ind = permutations[i * batch_size : (i+1) * batch_size]\n",
    "        batch_data = df[batch_ind, :]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        loss_vae_1, loss_vae_2, joint_kld_loss = loss_function_joint(batch_data, model1, model2)\n",
    "        loss = (loss_vae_1 + loss_vae_2 + 1000 * joint_kld_loss)\n",
    "        loss.backward()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(batch_data), len(df),\n",
    "                100. * i * len(batch_data)/ len(df),\n",
    "                loss.item() / len(batch_data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_joint(df, model1, model2, epoch):\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    test_loss = 0\n",
    "    inds = np.arange(df.shape[0])\n",
    "    with torch.no_grad():\n",
    "        for i in range(math.ceil(len(df)/batch_size)):\n",
    "            batch_ind = inds[i * batch_size : (i+1) * batch_size]\n",
    "            batch_data = df[batch_ind, :]\n",
    "            batch_data = batch_data.to(device)\n",
    "            loss_vae_1, loss_vae_2, joint_kld_loss = loss_function_joint(batch_data, model1, model2)\n",
    "        \n",
    "            test_loss += (loss_vae_1 + loss_vae_2 + 1000 * joint_kld_loss).item()\n",
    "\n",
    "\n",
    "    test_loss /= len(df)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_vanilla_vae = VAE(input_size, 200, 50)\n",
    "joint_vanilla_vae.to(device)\n",
    "\n",
    "joint_vae_gumbel = VAE_Gumbel(input_size, 200, 50, k = 50)\n",
    "joint_vae_gumbel.to(device)\n",
    "\n",
    "\n",
    "joint_optimizer = torch.optim.Adam(list(joint_vanilla_vae.parameters()) + list(joint_vae_gumbel.parameters()), \n",
    "                                                lr=lr, \n",
    "                                                betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2404 (0%)]\tLoss: 1764689.125000\n",
      "Train Epoch: 1 [1280/2404 (53%)]\tLoss: 93686.765625\n",
      "====> Epoch: 1 Average loss: 289752.5646\n",
      "====> Test set loss: 20543.1331\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_joint(train_data, joint_vanilla_vae, joint_vae_gumbel, joint_optimizer, epoch)\n",
    "    test_joint(test_data, joint_vanilla_vae, joint_vae_gumbel, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    train_pred = joint_vae_gumbel(train_data[0:64, :])[0]\n",
    "    train_pred[train_pred < 0.001] = 0 \n",
    "\n",
    "    test_pred = joint_vae_gumbel(test_data[0:64,:])[0]\n",
    "    test_pred[test_pred < 0.001] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6355, device='cuda:0')\n",
      "tensor(1.5679, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(torch.sum((train_pred - train_data[0:64, :]).abs()) / 64/500)\n",
    "    print(torch.sum((test_pred - test_data[0:64, :]).abs()) / 64/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1818, device='cuda:0')\n",
      "tensor(1105, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(test_pred[0,:] != 0))\n",
    "print(torch.sum(test_data[0,:] != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's actually Garph this.\n",
    "\n",
    "### Try it out at Gumbel sparsity of k = 10, 25, 50, 100, 250\n",
    "\n",
    "### Graph Test MSE Loss\n",
    "\n",
    "## Graph the mean activations at k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_activations(test_data, model, title, file):\n",
    "    preds, _, _, _ = model(test_data)\n",
    "    \n",
    "    pred_activations = preds.mean(dim = 0)\n",
    "    \n",
    "    test_activations = test_data.mean(dim = 0)\n",
    "    \n",
    "    x = np.arange(input_size) + 1\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(x, pred_activations.clone().detach().cpu().numpy(), label = 'Average Predictions')\n",
    "    plt.plot(x, test_activations.clone().detach().cpu().numpy(), label = 'Average Test Data')\n",
    "    \n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/ns3429/sparse-subset/vae_l1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-226-562a192bfcb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m graph_activations(test_data, model_l1_diag, 'Joint Gumbel vs Test Means', \n\u001b[0;32m----> 2\u001b[0;31m                   '/scratch/ns3429/sparse-subset/vae_l1.png')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-225-cf4b08eceb2e>\u001b[0m in \u001b[0;36mgraph_activations\u001b[0;34m(test_data, model, title, file)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2092\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                     \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m                 _png.write_png(renderer._renderer, fh,\n\u001b[1;32m    532\u001b[0m                                self.figure.dpi, metadata=metadata)\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch/ns3429/sparse-subset/vae_l1.png'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_activations(test_data, model_l1_diag, 'Joint Gumbel vs Test Means', \n",
    "                  '/scratch/ns3429/sparse-subset/vae_l1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 1.96 GiB total capacity; 1.15 GiB already allocated; 27.12 MiB free; 1.22 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-1633eff4adcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m graph_activations(test_data, joint_vae_gumbel, 'Joint Gumbel vs Test Means', \n\u001b[0;32m----> 2\u001b[0;31m                   '/scratch/ns3429/sparse-subset/joint_gumbel.png')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-225-cf4b08eceb2e>\u001b[0m in \u001b[0;36mgraph_activations\u001b[0;34m(test_data, model, title, file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgraph_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpred_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-212-0d47fb0243cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mmu_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mmu_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-212-0d47fb0243cc>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0msubset_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msubset_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-211-e5a7780ff259>\u001b[0m in \u001b[0;36msample_subset\u001b[0;34m(w, k, t)\u001b[0m\n\u001b[1;32m     38\u001b[0m     '''\n\u001b[1;32m     39\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgumbel_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontinuous_topk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-211-e5a7780ff259>\u001b[0m in \u001b[0;36mcontinuous_topk\u001b[0;34m(w, k, t, separate)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmax_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0monehot_approx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mEPSILON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkhot_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0monehot_approx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mkhot_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPSILON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkhot_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 1.96 GiB total capacity; 1.15 GiB already allocated; 27.12 MiB free; 1.22 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "graph_activations(test_data, joint_vae_gumbel, 'Joint Gumbel vs Test Means', \n",
    "                  '/scratch/ns3429/sparse-subset/joint_gumbel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 1.96 GiB total capacity; 1.19 GiB already allocated; 7.12 MiB free; 1.24 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-228-61df8f17b2ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m graph_activations(test_data, vae_gumbel_with_pre, 'Gumbel Matching Pretrained VAE vs Test Means', \n\u001b[0;32m----> 2\u001b[0;31m                   '/scratch/ns3429/sparse-subset/pretrained_gumbel.png')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-225-cf4b08eceb2e>\u001b[0m in \u001b[0;36mgraph_activations\u001b[0;34m(test_data, model, title, file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgraph_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpred_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-212-0d47fb0243cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mmu_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mmu_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-212-0d47fb0243cc>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0msubset_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msubset_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-211-e5a7780ff259>\u001b[0m in \u001b[0;36msample_subset\u001b[0;34m(w, k, t)\u001b[0m\n\u001b[1;32m     38\u001b[0m     '''\n\u001b[1;32m     39\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgumbel_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontinuous_topk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-211-e5a7780ff259>\u001b[0m in \u001b[0;36mcontinuous_topk\u001b[0;34m(w, k, t, separate)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmax_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0monehot_approx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mEPSILON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkhot_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0monehot_approx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mkhot_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPSILON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkhot_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 1.96 GiB total capacity; 1.19 GiB already allocated; 7.12 MiB free; 1.24 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "graph_activations(test_data, vae_gumbel_with_pre, 'Gumbel Matching Pretrained VAE vs Test Means', \n",
    "                  '/scratch/ns3429/sparse-subset/pretrained_gumbel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_all = [5, 10, 50, 100, 500, 1000, 2000, 3000]\n",
    "n_trials = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_pre = []\n",
    "losses_joint = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_all:\n",
    "    current_k_pre_losses = []\n",
    "    current_k_joint_losses = []\n",
    "    for trial_i in range(n_trials):\n",
    "        print(\"RUNNING for K {} Trial {}\".format(k, trial_i), flush=True)\n",
    "        vae_gumbel_with_pre = VAE_Gumbel(input_size, 200, 50, k = k)\n",
    "        vae_gumbel_with_pre.to(device)\n",
    "        vae_gumbel_with_pre_optimizer = torch.optim.Adam(vae_gumbel_with_pre.parameters(), \n",
    "                                                        lr=lr, \n",
    "                                                        betas = (b1,b2))\n",
    "    \n",
    "        joint_vanilla_vae = VAE(input_size, 200, 50)\n",
    "        joint_vanilla_vae.to(device)\n",
    "\n",
    "        joint_vae_gumbel = VAE_Gumbel(input_size, 200, 50, k = k)\n",
    "        joint_vae_gumbel.to(device)\n",
    "\n",
    "\n",
    "        joint_optimizer = torch.optim.Adam(list(joint_vanilla_vae.parameters()) + \n",
    "                                           list(joint_vae_gumbel.parameters()),\n",
    "                                                lr=lr, \n",
    "                                                betas = (b1,b2))\n",
    "    \n",
    "        for epoch in (1, n_epochs + 1):\n",
    "            train_pre_trained(train_data, vae_gumbel_with_pre, vae_gumbel_with_pre_optimizer, epoch, pretrain_vae)\n",
    "            train_joint(train_data, joint_vanilla_vae, joint_vae_gumbel, joint_optimizer, epoch)\n",
    "    \n",
    "        test_pred_pre = vae_gumbel_with_pre(test_data)[0]\n",
    "        test_pred_pre[test_pred_pre < 0.001] = 0 \n",
    "    \n",
    "        test_pred_joint = joint_vanilla_vae(test_data)[0]\n",
    "        test_pred_joint[test_pred_joint < 0.001] = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            mae_pre = torch.sum((test_pred_pre - test_data).abs()) / len(test_data) / 500\n",
    "            mae_joint = torch.sum((test_pred_joint - test_data).abs()) / len(test_data) / 500\n",
    "        \n",
    "        current_k_pre_losses.append(mae_pre.cpu().item())\n",
    "        current_k_joint_losses.append(mae_joint.cpu().item())\n",
    "        \n",
    "        # for freeing memory faster\n",
    "        del vae_gumbel_with_pre\n",
    "        del vae_gumbel_with_pre_optimizer\n",
    "        del joint_vanilla_vae\n",
    "        del joint_vae_gumbel\n",
    "        del joint_optimizer\n",
    "        del test_pred_pre\n",
    "        del test_pred_joint\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    \n",
    "    losses_pre.append(np.mean(current_k_pre_losses))\n",
    "    losses_joint.append(np.mean(current_k_joint_losses))\n",
    "    \n",
    "    \n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(k_all, losses_pre, label = 'Average MAE Losses with Gumbel Matching Pretrained')\n",
    "plt.plot(k_all, losses_joint, label = 'Average MAE Losses with Gumbel Joint Training')\n",
    "\n",
    "plt.title(\"Effect on Sparsity on MAE Loss\")\n",
    "plt.xlabel('Sparsity Level (Number of Non-Zero Features)')\n",
    "plt.ylabel('Per Neuron Average MAE Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('/scratch/ns3429/sparse-subset/comparing_across_sparsity.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nyu] *",
   "language": "python",
   "name": "conda-env-nyu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
