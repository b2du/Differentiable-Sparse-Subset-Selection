{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just get a quick sparsity overview of the methods so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import gc\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE_PATH_DATA = '../data/'\n",
    "BASE_PATH_DATA = '/scratch/ns3429/sparse-subset/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "b1 = 0.9\n",
    "b2 = 0.999\n",
    "img_size = 28\n",
    "channels = 1\n",
    "\n",
    "\n",
    "\n",
    "z_size = 500\n",
    "hidden_size = 1000\n",
    "\n",
    "n = 28 * 28\n",
    "\n",
    "# from running\n",
    "# EPSILON = np.finfo(tf.float32.as_numpy_dtype).tiny\n",
    "#EPSILON = 1.1754944e-38\n",
    "EPSILON = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Device\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sio.loadmat(BASE_PATH_DATA + 'zeisel/zeisel_data.mat')\n",
    "data= a['zeisel_data'].T\n",
    "N,d=data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(d):\n",
    "    #data[i,:]=data[i,:]/np.linalg.norm(data[i,:])\n",
    "    #mi = np.mean(data[:,i])\n",
    "    #std = np.std(data[:,i])\n",
    "    #data[:,i] = (data[:,i] - mi) / std\n",
    "    ma = np.max(data[:,i])\n",
    "    mi = np.min(data[:,i])\n",
    "    data[:, i] = (data[:, i] - mi) / (ma - mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09018117926614051"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data!=0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = np.random.permutation(np.arange(data.shape[0]))\n",
    "upto = int(.8 * len(data))\n",
    "\n",
    "train_data = data[slices[:upto]]\n",
    "test_data = data[slices[upto:]]\n",
    "\n",
    "train_data = Tensor(train_data).to(device)\n",
    "test_data = Tensor(test_data).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2263)\n",
      "tensor(0.2223)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.std(dim = 0).mean())\n",
    "print(test_data.std(dim = 0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does L1 work if we normalize after every step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l1_diag = VAE_l1_diag(input_size, hidden_size, z_size)\n",
    "\n",
    "model_l1_diag.to(device)\n",
    "model_l1_optimizer = torch.optim.Adam(model_l1_diag.parameters(), \n",
    "                                            lr=lr,\n",
    "                                            betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2404 (0%)]\tLoss: 11413.724609\n",
      "Train Epoch: 1 [1280/2404 (53%)]\tLoss: 3157.709961\n",
      "====> Epoch: 1 Average loss: 3709.6169\n",
      "====> Test set loss: 2789.4660\n",
      "Train Epoch: 2 [0/2404 (0%)]\tLoss: 3056.877930\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9f6d9fc62b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mtrain_l1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_l1_diag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_l1_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_l1_diag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/NYU/SecondYear/SecondSemester/Differentiable-Sparse-Subset-Selection/notebooks/utils.py\u001b[0m in \u001b[0;36mtrain_l1\u001b[0;34m(df, model, optimizer, epoch, batch_size)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function_per_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "        train_l1(train_data, model_l1_diag, model_l1_optimizer, epoch, batch_size)\n",
    "        test(test_data, model_l1_diag, epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [10**(-i) for i in range(10)]\n",
    "bins.reverse()\n",
    "bins += [10]\n",
    "print(np.histogram(model_l1_diag.diag.abs().clone().detach().cpu().numpy(), bins = bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_model_summary(model_l1_diag, train_data, test_data, 0.1, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try Pretrained VAE and then gumble trick with it\n",
    "\n",
    "Then try joint training VAE and Gumbel Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain VAE First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_vae = VAE(input_size, hidden_size, z_size)\n",
    "\n",
    "pretrain_vae.to(device)\n",
    "pretrain_vae_optimizer = torch.optim.Adam(pretrain_vae.parameters(), \n",
    "                                            lr=lr,\n",
    "                                            betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2404 (0%)]\tLoss: 6447.793945\n",
      "Train Epoch: 1 [1280/2404 (53%)]\tLoss: 3060.293457\n",
      "====> Epoch: 1 Average loss: 3516.2642\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-009718ec4a9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain_vae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain_vae_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain_vae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/NYU/SecondYear/SecondSemester/Differentiable-Sparse-Subset-Selection/notebooks/utils.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(df, model, epoch, batch_size)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0minds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "        train(train_data, pretrain_vae, pretrain_vae_optimizer, epoch, batch_size)\n",
    "        test(test_data, pretrain_vae, epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_model_summary(pretrain_vae, train_data, test_data, 0.1, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pretrain_vae.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_vae.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Gumbel with the Pre-Trained VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_gumbel_with_pre = VAE_Gumbel(input_size, hidden_size, z_size, k = 50)\n",
    "vae_gumbel_with_pre.to(device)\n",
    "vae_gumbel_with_pre_optimizer = torch.optim.Adam(vae_gumbel_with_pre.parameters(), \n",
    "                                                lr=lr, \n",
    "                                                betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2404 (0%)]\tLoss: 802522.687500\n",
      "Train Epoch: 1 [1280/2404 (53%)]\tLoss: 51021.445312\n",
      "====> Epoch: 1 Average loss: 162977.3032\n",
      "====> Test set loss: 6603.3549\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "        train_pre_trained(train_data, vae_gumbel_with_pre, vae_gumbel_with_pre_optimizer, \n",
    "                          epoch, pretrain_vae, batch_size)\n",
    "        test(test_data, vae_gumbel_with_pre, epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1881, device='cuda:0')\n",
      "tensor(1105, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "quick_model_summary(vae_gumbel_with_pre, train_data, test_data, 0.1, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_vanilla_vae = VAE(input_size, hidden_size, z_size)\n",
    "joint_vanilla_vae.to(device)\n",
    "\n",
    "joint_vae_gumbel = VAE_Gumbel(input_size, hidden_size, z_size, k = 50)\n",
    "joint_vae_gumbel.to(device)\n",
    "\n",
    "\n",
    "joint_optimizer = torch.optim.Adam(list(joint_vanilla_vae.parameters()) + list(joint_vae_gumbel.parameters()), \n",
    "                                                lr=lr, \n",
    "                                                betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2404 (0%)]\tLoss: 1764689.125000\n",
      "Train Epoch: 1 [1280/2404 (53%)]\tLoss: 93686.765625\n",
      "====> Epoch: 1 Average loss: 289752.5646\n",
      "====> Test set loss: 20543.1331\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_joint(train_data, joint_vanilla_vae, joint_vae_gumbel, joint_optimizer, epoch, batch_size)\n",
    "    test_joint(test_data, joint_vanilla_vae, joint_vae_gumbel, epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1818, device='cuda:0')\n",
      "tensor(1105, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "quick_model_summary(joint_vae_gumbel, train_data, test_data, 0.1, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del joint_vanilla_vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's actually Graph this.\n",
    "\n",
    "### Try it out at Gumbel sparsity of k = 10, 25, 50, 100, 250\n",
    "\n",
    "### Graph Test MSE Loss\n",
    "\n",
    "## Graph the mean activations at k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_activations(test_data, model, title, file):\n",
    "    preds, _, _ = model(test_data)\n",
    "    \n",
    "    preds[preds < 0.09] = 0\n",
    "    pred_activations = preds.mean(dim = 0)\n",
    "    \n",
    "    test_activations = test_data.mean(dim = 0)\n",
    "    \n",
    "    x = np.arange(input_size) + 1\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(x, pred_activations.clone().detach().cpu().numpy(), label = 'Average Predictions')\n",
    "    plt.plot(x, test_activations.clone().detach().cpu().numpy(), label = 'Average Test Data')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.ylim([-0.1, 1])\n",
    "    plt.xlabel(\"Feature Index\")\n",
    "    plt.ylabel(\"Average Activation of Feature\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_sparsity(test_data, model, title, file):\n",
    "    preds, _, _ = model(test_data)\n",
    "    \n",
    "    preds[preds < 0.09] = 0\n",
    "    preds[preds >= 0.09] = 1\n",
    "    \n",
    "    pred_count = preds.sum(dim = 0) / len(test_data)\n",
    "    \n",
    "    test_count = test_data.sum(dim = 0) / len(test_data)\n",
    "    \n",
    "    x = np.arange(input_size) + 1\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(x, pred_count.clone().detach().cpu().numpy(), label = 'Count NonZero Predictions')\n",
    "    plt.plot(x, test_count.clone().detach().cpu().numpy(), label = 'Count NonZero Test Data')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.ylim([-0.1, 1])\n",
    "    plt.xlabel(\"Feature Index\")\n",
    "    plt.ylabel(\"Proportion of Test Set Feature Was not Sparse\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/ns3429/sparse-subset/vae_l1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-2df21b98f588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m graph_activations(test_data, pretrain_vae, 'Joint Gumbel vs Test Means', \n\u001b[0;32m----> 2\u001b[0;31m                   '/scratch/ns3429/sparse-subset/vae_l1.png')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-8a5d57110912>\u001b[0m in \u001b[0;36mgraph_activations\u001b[0;34m(test_data, model, title, file)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2092\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                     \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m                 _png.write_png(renderer._renderer, fh,\n\u001b[1;32m    532\u001b[0m                                self.figure.dpi, metadata=metadata)\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch/ns3429/sparse-subset/vae_l1.png'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_activations(test_data, model_l1_diag, 'Joint Gumbel vs Test Means', \n",
    "                  '/scratch/ns3429/sparse-subset/vae_l1_activations.png')\n",
    "graph_sparsity(test_data, model_l1_diag, 'Joint Gumbel vs Test Sparsity', \n",
    "                  '/scratch/ns3429/sparse-subset/vae_l1_sparsity.png')\n",
    "\n",
    "del model_l1_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joint_vae_gumbel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1633eff4adcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m graph_activations(test_data, joint_vae_gumbel, 'Joint Gumbel vs Test Means', \n\u001b[0m\u001b[1;32m      2\u001b[0m                   '/scratch/ns3429/sparse-subset/joint_gumbel.png')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'joint_vae_gumbel' is not defined"
     ]
    }
   ],
   "source": [
    "graph_activations(test_data, joint_vae_gumbel, 'Joint Gumbel vs Test Means', \n",
    "                  '/scratch/ns3429/sparse-subset/joint_gumbel_activations.png')\n",
    "graph_sparsity(test_data, joint_vae_gumbel, 'Joint Gumbel vs Test Sparsity', \n",
    "                  '/scratch/ns3429/sparse-subset/joint_gumbel_sparsity.png')\n",
    "\n",
    "del joint_vae_gumbel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 1.96 GiB total capacity; 1.19 GiB already allocated; 7.12 MiB free; 1.24 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-228-61df8f17b2ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m graph_activations(test_data, vae_gumbel_with_pre, 'Gumbel Matching Pretrained VAE vs Test Means', \n\u001b[0;32m----> 2\u001b[0;31m                   '/scratch/ns3429/sparse-subset/pretrained_gumbel.png')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-225-cf4b08eceb2e>\u001b[0m in \u001b[0;36mgraph_activations\u001b[0;34m(test_data, model, title, file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgraph_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpred_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nyu/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-212-0d47fb0243cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mmu_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mmu_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-212-0d47fb0243cc>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0msubset_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msubset_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-211-e5a7780ff259>\u001b[0m in \u001b[0;36msample_subset\u001b[0;34m(w, k, t)\u001b[0m\n\u001b[1;32m     38\u001b[0m     '''\n\u001b[1;32m     39\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgumbel_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontinuous_topk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-211-e5a7780ff259>\u001b[0m in \u001b[0;36mcontinuous_topk\u001b[0;34m(w, k, t, separate)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmax_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0monehot_approx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mEPSILON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkhot_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0monehot_approx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mkhot_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPSILON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkhot_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 1.96 GiB total capacity; 1.19 GiB already allocated; 7.12 MiB free; 1.24 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "graph_activations(test_data, vae_gumbel_with_pre, 'Gumbel Matching Pretrained VAE vs Test Means', \n",
    "                  '/scratch/ns3429/sparse-subset/pretrained_gumbel_activations.png')\n",
    "graph_sparsity(test_data, vae_gumbel_with_pre, 'Gumbel Matching Pretrained VAE vs Test Sparsity', \n",
    "                  '/scratch/ns3429/sparse-subset/pretrained_gumbel_sparsity.png')\n",
    "\n",
    "del vae_gumbel_with_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_all = [5, 10, 25, 50, 75, 100, 150]#, 250, 500, 1000, 2000, 3000]\n",
    "n_trials = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_pre = []\n",
    "losses_joint = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_all:\n",
    "    current_k_pre_losses = []\n",
    "    current_k_joint_losses = []\n",
    "    for trial_i in range(n_trials):\n",
    "        print(\"RUNNING for K {} Trial {}\".format(k, trial_i), flush=True)\n",
    "        vae_gumbel_with_pre = VAE_Gumbel(input_size, hidden_size, z_size, k = k)\n",
    "        vae_gumbel_with_pre.to(device)\n",
    "        vae_gumbel_with_pre_optimizer = torch.optim.Adam(vae_gumbel_with_pre.parameters(), \n",
    "                                                        lr=lr, \n",
    "                                                        betas = (b1,b2))\n",
    "    \n",
    "        joint_vanilla_vae = VAE(input_size, hidden_size, z_size)\n",
    "        joint_vanilla_vae.to(device)\n",
    "\n",
    "        joint_vae_gumbel = VAE_Gumbel(input_size, hidden_size, z_size, k = k)\n",
    "        joint_vae_gumbel.to(device)\n",
    "\n",
    "\n",
    "        joint_optimizer = torch.optim.Adam(list(joint_vanilla_vae.parameters()) + \n",
    "                                           list(joint_vae_gumbel.parameters()),\n",
    "                                                lr=lr, \n",
    "                                                betas = (b1,b2))\n",
    "    \n",
    "        for epoch in (1, n_epochs + 1):\n",
    "            train_pre_trained(train_data, vae_gumbel_with_pre, vae_gumbel_with_pre_optimizer, \n",
    "                              epoch, pretrain_vae, batch_size)\n",
    "            train_joint(train_data, joint_vanilla_vae, joint_vae_gumbel, joint_optimizer, epoch, batch_size)\n",
    "    \n",
    "        test_loss_pre = 0\n",
    "        test_loss_joint = 0\n",
    "        \n",
    "        inds = np.arange(test_data.shape[0])\n",
    "        with torch.no_grad():\n",
    "            for i in range(math.ceil(len(test_data)/batch_size)):\n",
    "                batch_ind = inds[i * batch_size : (i+1) * batch_size]\n",
    "                batch_data = test_data[batch_ind, :]\n",
    "                \n",
    "                test_pred_pre = vae_gumbel_with_pre(batch_data)[0]\n",
    "                test_pred_joint = joint_vae_gumbel(batch_data)[0]\n",
    "                \n",
    "                test_pred_pre[test_pred_pre < 0.09] = 0\n",
    "                test_pred_joint[test_pred_joint < 0.09] = 0\n",
    "                \n",
    "                test_loss_pre += F.binary_cross_entropy(test_pred_pre, batch_data, reduction='sum')\n",
    "                test_loss_joint += F.binary_cross_entropy(test_pred_joint, batch_data, reduction='sum')\n",
    "                \n",
    "                del batch_data\n",
    "            \n",
    "        test_loss_pre /= len(test_df)\n",
    "        test_loss_joint /= len(test_df)\n",
    "        current_k_pre_losses.append(test_loss_pre.cpu().item())\n",
    "        current_k_joint_losses.append(test_loss_joint.cpu().item())\n",
    "        \n",
    "        # for freeing memory faster\n",
    "        del vae_gumbel_with_pre\n",
    "        del vae_gumbel_with_pre_optimizer\n",
    "        del joint_vanilla_vae\n",
    "        del joint_vae_gumbel\n",
    "        del joint_optimizer\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    \n",
    "    losses_pre.append(np.mean(current_k_pre_losses))\n",
    "    losses_joint.append(np.mean(current_k_joint_losses))\n",
    "    \n",
    "    \n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(k_all, losses_pre, label = 'Average BCE Losses with Gumbel Matching Pretrained')\n",
    "plt.plot(k_all, losses_joint, label = 'Average BCE Losses with Gumbel Joint Training')\n",
    "\n",
    "plt.title(\"Effect on Sparsity on BCE Loss\")\n",
    "plt.xlabel('Sparsity Level (Number of Non-Zero Features)')\n",
    "plt.ylabel('Per Neuron Average BCE Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('/scratch/ns3429/sparse-subset/comparing_across_sparsity.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nyu] *",
   "language": "python",
   "name": "conda-env-nyu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
